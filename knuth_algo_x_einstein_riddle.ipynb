{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knuth's X algorithm basics\n",
    "\n",
    "Below are classes that implement elements out of which the sparse matrix used in Knuth's X algorithm will be build. The idea is pretty straightforward - each class is a quite literal impementation of waht his paper describes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.up = self\n",
    "        self.down = self\n",
    "        self.left = self\n",
    "        self.right = self\n",
    "        self.COL = None\n",
    "        self.ROW = None\n",
    "\n",
    "    def hideInCol(self):\n",
    "        self.up.down = self.down\n",
    "        self.down.up = self.up\n",
    "        self.COL.row_count -= 1\n",
    "        return self\n",
    "\n",
    "    def showInCol(self):\n",
    "        self.up.down = self\n",
    "        self.down.up = self\n",
    "        self.COL.row_count += 1\n",
    "        return self\n",
    "\n",
    "    def hideInRow(self):\n",
    "        self.left.right = self.right\n",
    "        self.right.left = self.left\n",
    "        return self\n",
    "\n",
    "    def showInRow(self):\n",
    "        self.left.right = self\n",
    "        self.right.left = self\n",
    "        return self\n",
    "    \n",
    "    def deleteUnuseableRow(self):\n",
    "        cur_cell = self.right \n",
    "        while cur_cell != self:\n",
    "            print(cur_cell.COL.label)\n",
    "            cur_cell.hideInCol()\n",
    "            cur_cell = cur_cell.right\n",
    "        print(\"done\")\n",
    "        self.hideInCol()\n",
    "        return\n",
    "\n",
    "    def hideWholeRow(self, start = None):\n",
    "        if start == None: # if we just started the loop, don't hide me from my column, but go to my neighbor\n",
    "            self.right.hideWholeRow(start = self)\n",
    "            return\n",
    "        if start != self: # we are not first and not last => hide me and continue\n",
    "            self.hideInCol()\n",
    "            self.right.hideWholeRow(start = start)\n",
    "            return\n",
    "        return # last possibility start == self => we have looped and can finish\n",
    "\n",
    "    def showWholeRow(self, start = None):\n",
    "        if start == None: # if we just started the loop, don't hide me from my column, but go to my neighbor\n",
    "            self.left.showWholeRow(start = self)\n",
    "            return\n",
    "        if start != self: # we are not first and not last => hide me and continue\n",
    "            self.showInCol()\n",
    "            self.left.showWholeRow(start = start)\n",
    "            return\n",
    "        return # last possibility start == self => we have looped and can finish\n",
    "    \n",
    "    def getNeighbor(self, direction, by=0):\n",
    "        neighbor = {\n",
    "            'left'  : self.left,\n",
    "            'right' : self.right,\n",
    "            'up'    : self.up,\n",
    "            'down'  : self.down\n",
    "        }[direction]\n",
    "        if by > 0:\n",
    "            return neighbor.getNeighbor(direction, by = by-1)\n",
    "        return neighbor\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        return f\"<root node>\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class columnHeader(node):\n",
    "\n",
    "    def __init__(self, label):\n",
    "        super().__init__()\n",
    "        self.label = label\n",
    "        self.row_count = 0\n",
    "        self.COL = self\n",
    "\n",
    "    def hideMe(self):\n",
    "        self.hideInRow()\n",
    "        cell = self.down\n",
    "        while cell != self:\n",
    "            cell.hideWholeRow()\n",
    "            cell = cell.down\n",
    "        return self\n",
    "\n",
    "    def showMe(self):\n",
    "        self.showInRow()\n",
    "        cell = self.up\n",
    "        while cell != self:\n",
    "            cell.showWholeRow()\n",
    "            cell = cell.up\n",
    "        return self\n",
    "\n",
    "    def appendRow(self, row):\n",
    "        row.down = self\n",
    "        row.up = self.up\n",
    "        self.up.down = row\n",
    "        self.up = row\n",
    "        row.COL = self\n",
    "        self.row_count += 1\n",
    "        return self\n",
    "\n",
    "    def addToRoot(self, root):\n",
    "        root.appendColumn(self)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        return f\"<(col) {self.label}>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rowHeader(node):\n",
    "    \n",
    "    def __init__(self, label):\n",
    "        super().__init__()\n",
    "        self.label = label\n",
    "        self.ROW = self\n",
    "\n",
    "    def appendColumn(self, col):\n",
    "        col.right = self\n",
    "        col.left = self.left\n",
    "        self.left.right = col\n",
    "        self.left = col\n",
    "        col.ROW = self\n",
    "        return self\n",
    "\n",
    "    def addToRoot(self, root):\n",
    "        root.appendRow(self)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        return f\"<(row) {self.label}>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rootNode(columnHeader, rowHeader):\n",
    "\n",
    "    def __init__(self):\n",
    "        node.__init__(self)\n",
    "        self.row_count = 0\n",
    "        self.label = None\n",
    "        self.ROW = self\n",
    "        self.COL = self\n",
    "\n",
    "    def addToRoot(self, root):\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        return f\"<(node) {self.label}>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_tuples(dict):\n",
    "\n",
    "    \"\"\"\n",
    "    dictionaries are sometimes cumbersone in addressing, so I will often transform them into a list of tuples\n",
    "    \"\"\"\n",
    "\n",
    "    return [(k, v) for k, v in dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuples_to_dicts(tuples):\n",
    "\n",
    "    \"\"\"\n",
    "    inverse of the above\n",
    "    \"\"\"\n",
    "\n",
    "    return { t[0]: t[1] for t in tuples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_simple_criterion(personal_attributes, criterion_attributes):\n",
    "\n",
    "    \"\"\"Given two sets of attributes (each represented as a dictionary of (dimension name : dimension value) it checks if the attributes match. The idea is:\n",
    "    - sparse_matrix_row_attr - is the target: the list of attributes to be checked\n",
    "    - check_attr - is the soruce:  the conditions to check against\n",
    "    then\n",
    "    1. if any dim from conditions is missing in target, check cannot be perfomed and defaults to OK\n",
    "    2. otherwise, for the common dimensions we check:\n",
    "        a. if all values match - OK\n",
    "        b. otherwise - FAIL\n",
    "    \"\"\"\n",
    "    \n",
    "    has_dims = {k[0] for k in personal_attributes}\n",
    "    needs_dims = {k[0] for k in criterion_attributes}\n",
    "    overlap_attrs = has_dims & needs_dims\n",
    "\n",
    "    can_be_checked = overlap_attrs == criterion_attributes\n",
    "\n",
    "    # not enough attributes present to perform the  check => default to OK\n",
    "    if not can_be_checked:\n",
    "        return True\n",
    "\n",
    "    # check on each dimension OK => all OK\n",
    "    target = tuples_to_dicts(personal_attributes)\n",
    "    source = tuples_to_dicts(criterion_attributes)\n",
    "\n",
    "    summary_check_result = { target[d] == source[d] for d in overlap_attrs } \n",
    "    \n",
    "\n",
    "    return summary_check_result == {True} or summary_check_result == {False}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_set_of_criteria(personal_attributes, known_identity_criteria):\n",
    "\n",
    "    \"\"\"\n",
    "    for a single target (sparse_matrix_row_attr) it applies the check across\n",
    "    a set of different source conditions (check_set). Result is OK <=> each single check is OK.\n",
    "    To see what 'source' and what 'target' mean in this context, check the description of check_simple_criterion()\n",
    "    \"\"\"\n",
    "\n",
    "    summary_check_results = {\n",
    "        check_simple_criterion(personal_attributes, item)\n",
    "        for item in known_identity_criteria\n",
    "    }\n",
    "    \n",
    "    return summary_check_results == {True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's go\n",
    "\n",
    "## 1. read the riddle file\n",
    "\n",
    "First we read in the YML fiel describing the riddle. For notes on how to cosntruct such a file, consult the readme.md in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riddle_file = \"input_1_einstein.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(riddle_file) as f:\n",
    "    try:\n",
    "        riddle_text= yaml.safe_load(f)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. reshape data\n",
    "\n",
    "we then reshape the read in data into something easier to handle downstream. This is neither part of Knuth's algorithm, nor critical to how it was implemented here to solve Zebra Riddles. I jsut made a (poor?) design decision to have very copmpact input fil3s, but they need to be reshaped before use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 reshape \"simple conditions\"\n",
    "\n",
    "This part cosntructs a list of \"simple conditions\".\n",
    "\n",
    "A simple condition is one that is along the lines of\n",
    "\n",
    "> Person who `Attrribute A` also is `Attrribute B`\n",
    "\n",
    "encoded in the file as \n",
    "\n",
    "> ```yaml\n",
    "> - ...\n",
    "> - first_attribute_dimension_name : first_attribute_value\n",
    ">   second_attribute_dimension_name : second_attribute_value\n",
    "> - ...\n",
    "> ```\n",
    "\n",
    "Since each characteristic is alwasy comrpised of dimension (e.g. \"house color\" or \"favourite drink\") and the value on that dimension (\"green\" or \"milk\"), eventually each entry on the list (each \"condition\") is effectively strucuted as a dictionary:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"type\" : \"_is\", # fixed value. redundant here, but kept to be easier to align with following data strucutres\n",
    "    \"params\" : [ # here order does not matter\n",
    "        (\n",
    "            first_attribute_dimension_name,\n",
    "            first_attribute_value \n",
    "        ),\n",
    "        (\n",
    "            second_attribute_dimension_name,\n",
    "            second_attribute_value \n",
    "        )\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "i.e. \"The `Spaniard` (`nationality`) owns the `dog` (`pet`).\" will be encoded as \n",
    "\n",
    "> ```yaml\n",
    "> - ...\n",
    "> - nationality : Spanish\n",
    ">   pet : dog\n",
    "> - ...\n",
    "> ```\n",
    "\n",
    "and represented as a following data structure\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"type\" : \"_is\", \n",
    "    \"params\" : [ \n",
    "        ('nationality', 'Spanish'),\n",
    "        ('pet',  'dog')\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalities_list = [ \n",
    "    {\n",
    "        \"type\" : \"_is\",\n",
    "        \"params\" : dict_to_tuples(is_condition)\n",
    "    }\n",
    "    for is_condition in riddle_text\n",
    "       if len(is_condition) > 1\n",
    "]\n",
    "\n",
    "equalities_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 reshape \"neighbor\" conditions\n",
    "\n",
    "this is the part where we untangle and reshape all condition in the form\n",
    "\n",
    "\n",
    "> Person who `Attrribute A` lives in a house next to person who `Attrribute B`\n",
    "\n",
    "The encoding is quite the same as above, with the difference that the `\"type\" : \"_is\"` fixed value is replaced by one denoting the neighborly relationship:\n",
    "\n",
    "* `_left` - in case the person described by firt attribute on the list lives left (house number **less by 1**) of the person described by the second attribute\n",
    "* `_left` - in case the person described by firt attribute on the list lives right (house number **increased by 1**) of the person described by the second attribute\n",
    "* `_adj` (adjacent) - in case the two menioned persons live next to each other, but we don't knwo who lives on which side.\n",
    "\n",
    "Example:\n",
    "\n",
    "> The `green` [`colored`] house is immediately to *`the right`* of the house whoe owner `drink` `tea`.\n",
    "\n",
    "would be encoded as \n",
    "\n",
    "> ```yaml\n",
    "> - ...\n",
    "> - _right:\n",
    ">   - color: green\n",
    ">   - drink: tea\n",
    "> - ...\n",
    "> ```\n",
    "\n",
    "and represented as a following data structure\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"type\" : \"_right\", \n",
    "    \"params\" : [\n",
    "        ('color', 'green'),\n",
    "        ('drink', 'tea')\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_list = [\n",
    "    {\n",
    "        \"type\" : condition_name,\n",
    "        \"params\" : [\n",
    "            attr\n",
    "            for item in neighbor_condition[condition_name]\n",
    "            for attr in dict_to_tuples(item)\n",
    "        ]\n",
    "    }\n",
    "    for neighbor_condition in riddle_text\n",
    "    for condition_name, condition_params in neighbor_condition.items() \\\n",
    "        if condition_name in ['_left', '_right', '_adj']\n",
    "]\n",
    "\n",
    "neighbors_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 reshape other data\n",
    "\n",
    "The only other piece of information we can get is the attribute encoded in the question.\n",
    "\n",
    "the data structure is the same, but we replace `\"type\" : \"_is\"` with  `\"type\" : \"_question\"`.\n",
    "\n",
    "So the question\n",
    "\n",
    "> Now, who `drinks` `water`? Who owns the [`pet`] `zebra`?\n",
    "\n",
    "woudl be encoded as \n",
    "\n",
    "```yaml\n",
    "- ...\n",
    "- _question:\n",
    "  - drink : water\n",
    "  - pet : zebra\n",
    "- ...\n",
    "```\n",
    "\n",
    "and represented as a following data structure\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"type\" : \"_question\", \n",
    "    \"params\" : [\n",
    "        ('drink', 'water'),\n",
    "        ('pet', 'zebra')\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_values = [\n",
    "    {\n",
    "        \"type\" : condition_name,\n",
    "        \"params\" : [\n",
    "            attr\n",
    "            for item in neighbor_condition[condition_name]\n",
    "            for attr in dict_to_tuples(item)\n",
    "        ]\n",
    "    }\n",
    "    for neighbor_condition in riddle_text\n",
    "    for condition_name, condition_params in neighbor_condition.items() \\\n",
    "        if condition_name in ['_question']\n",
    "]\n",
    "\n",
    "other_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 collate all data\n",
    "\n",
    "a list of all constraints to be used downstream\n",
    "Once we compiled all known attributes described in the riddle, we cna cosntruct a dictionary of dimentions.\n",
    "\n",
    "Each entry is the name of the dimension and a set of all it's possible values. An additional dimension named `_#` is added, that contains all possible house positions (1-based indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_constraints = equalities_list + neighbors_list + other_values\n",
    "\n",
    "all_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class einstein_matrix:\n",
    "\n",
    "    \"\"\"\n",
    "    This is a class to contain and manage all operations related to cosntructing and using the sparse matrix used in Knuth's X algorithm\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    constraints : list\n",
    "        a list of all constraints defined in the riddle\n",
    "    dicts : dictionary\n",
    "        a dictionary of all dimensions implied by the constraints\n",
    "    matrix_root : rootNode\n",
    "        the root of the matrix, whera ll other nodes are (possibly indirectly) linked\n",
    "     column_headers_dir : dictionary\n",
    "        a directory of all column headers created for the matrix, indexed in a way\n",
    "        that makes lookup easier the lookup happens when rows are linked to columns\n",
    "        when the matrix is populated\n",
    "    row_headers_dir : dictionary\n",
    "        a directory of all row headers created for the matrix.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    deduce_dimensions()\n",
    "        deduces all riddle dimensions from known constraints\n",
    "    create_row_labels()\n",
    "        Constructs a list of persons that have viable attributes along with a text label for the matrix row.\n",
    "    create_rows()\n",
    "        Creates all rowHeader objects \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, list_of_constraints):\n",
    "\n",
    "        self.constraints = list_of_constraints\n",
    "        self.dicts = self.deduce_dimensions()\n",
    "        self.matrix_root = rootNode()\n",
    "        self.simple_row_headers_dir = []\n",
    "        self.simple_column_headers_dir = {\n",
    "            \"_is\" : {},\n",
    "            \"_first\" : {},\n",
    "            \"_second\" : {}\n",
    "        }    \n",
    "\n",
    "    def deduce_dimensions(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Transforms known cosntraints into a list of all possible dimensions (dimension names) with all possible values of each dimension\n",
    "        \"\"\"\n",
    "\n",
    "        all_attrs = [p for constraint in self.constraints for p in constraint[\"params\"] ]\n",
    "\n",
    "        dicts = {i[0] : set() for i in all_attrs}\n",
    "        [dicts[i[0]].add(i[1]) for i in all_attrs]\n",
    "            \n",
    "        max_items = max([len(dim) for dim in dicts.values()])\n",
    "        dicts['_#'] = {r+1 for r in range(max_items)}\n",
    "\n",
    "        return dicts\n",
    "\n",
    "    def create_row_labels(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Takes the dictionary of dimensions and known simple (not \"neighbor\") constraints and constructs a list of persons that have allowed attributes along with a text label for the matrix row. The cosntruction is iterative (dimension by dimension, value by value).\n",
    "        As we iterate,a ny combination of attributes that is known to violate the indeintity cosntraints will be discarded \n",
    "        \"\"\"\n",
    "    \n",
    "        labels = [set()]\n",
    "\n",
    "        guards = [constraint[\"params\"] for constraint in self.constraints if constraint[\"type\"] == \"_is\"]\n",
    "\n",
    "        for dim_name, dim_values in self.dicts.items():\n",
    "            labels = [\n",
    "                label | {(dim_name, value)}\n",
    "                for label in labels \n",
    "                for value in dim_values\n",
    "                    if check_set_of_criteria(\n",
    "                        label | {(dim_name, value)},\n",
    "                        guards\n",
    "                    )\n",
    "            ]\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def create_simple_rows(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Creates all rowHeader objects representing possible persons (combinations of attributes) and adds them to the matrix's root node and registers each row in the row directory for easier lookup\n",
    "        \"\"\"\n",
    "        \n",
    "        labels = self.create_row_labels()\n",
    "\n",
    "        self.simple_row_headers_dir = [\n",
    "            {\n",
    "            \"attrs\" : label,\n",
    "            \"node\" : rowHeader(\n",
    "                    \":\".join([\n",
    "                        str(attr[1]) for attr in label\n",
    "                    ])\n",
    "                ).addToRoot(self.matrix_root)\n",
    "            }\n",
    "            for label in labels\n",
    "        ]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def create_complex_rows():\n",
    "\n",
    "        \"\"\"\n",
    "        creates all the additional rows representing combined  neighbour pairs, for neighbour consstraints without specified direction, e.g. in the form \"person X livex nextto person Y\"\n",
    "        \"\"\"\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def create_equality_columns(self):\n",
    "\n",
    "        \"\"\"\n",
    "        creates all columnHEader objects for each \"simple\" - i.e. the identity - constraint\n",
    "        \"\"\"\n",
    "\n",
    "        for dim_name, dim_values in self.dicts.items():\n",
    "\n",
    "            for val in dim_values:\n",
    "\n",
    "                label = f\"{dim_name}:{val}\"\n",
    "                node = columnHeader(label).addToRoot(self.matrix_root)\n",
    "                self.column_headers_dir[\"_is\"][(dim_name, val)] = node\n",
    "\n",
    "        return self\n",
    "\n",
    "    def create_simple_neighbor_columns(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Creates columns for the \"neighbor\" constraints, i.e. ones in the form \"Person with the attribute X lives next to person with attribure Y\"\n",
    "        \"\"\"\n",
    "\n",
    "        neighbors_constraints = [c for c in self.constraints if c[\"type\"] in ['_left', '_right']]\n",
    "        number_of_houses = len(self.dicts.get(\"_#\"))\n",
    "\n",
    "        for constr in neighbors_constraints:\n",
    "\n",
    "            direction = constr[\"type\"]\n",
    "            first_attr = constr[\"params\"][0]\n",
    "            second_attr = constr[\"params\"][1]\n",
    "\n",
    "            dir_lbl = dir_label_map.get(direction, \"?\")\n",
    "\n",
    "            if direction  == \"_right\":\n",
    "                first_house = 1\n",
    "                last_house = number_of_houses - 1\n",
    "            else:\n",
    "                first_house = 2\n",
    "                last_house = number_of_houses\n",
    "            \n",
    "            first_dir = self.simple_column_headers_dir[\"_first\"]\n",
    "            first_dir[first_attr] = first_dir.get(first_attr, {})\n",
    "            first_dir = first_dir[first_attr]\n",
    "\n",
    "            second_dir = self.simple_column_headers_dir[\"_second\"]\n",
    "            second_dir[second_attr] = second_dir.get(second_attr, {})\n",
    "            second_dir = second_dir[second_attr]\n",
    "\n",
    "            for h in range(first_house, last_house + 1):\n",
    "                \n",
    "                if direction == \"_right\":\n",
    "                    label_txt = f\"{second_attr[0]}:{second_attr[1]} {dir_lbl} {first_attr[0]}:{first_attr[1]} ({h})\"\n",
    "                else:\n",
    "                    label_txt = f\"{first_attr[0]}:{first_attr[1]} {dir_lbl} {second_attr[0]}:{second_attr[1]} ({h})\"\n",
    "                \n",
    "                node = columnHeader(label_txt).addToRoot(self.matrix_root)\n",
    "\n",
    "                first_dir[h] = node\n",
    "                second_dir[h] = node\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = einstein_matrix(all_constraints)\n",
    "em.create_simple_neighbor_columns()\n",
    "#em.create_neighbor_columns()\n",
    "print(\"=== _dir_first ===\")\n",
    "for k, v in em.simple_column_headers_dir[\"_first\"].items():\n",
    "    print(k)\n",
    "    for i, n in v.items():\n",
    "        print(f\"   {i} : {n}\")\n",
    "print(\" === _dir_second ===\")\n",
    "for k, v in em.simple_column_headers_dir[\"_second\"].items():\n",
    "    print(k)\n",
    "    for i, n in v.items():\n",
    "        print(f\"   {i} : {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(matrix, solution=[], log=[], k=0):\n",
    "\n",
    "    if type(matrix) != rootNode:\n",
    "        raise TypeError(\"Must start with matrix root node\")\n",
    "\n",
    "    # solution found if matrix is empty\n",
    "    if matrix.right == matrix:\n",
    "        print(\"ready\")\n",
    "        return prep_solution(solution)\n",
    "\n",
    "    # select column\n",
    "    col = matrix.right\n",
    "    tmp_col = col\n",
    "    while tmp_col != matrix:\n",
    "        if tmp_col.row_count < col.row_count:\n",
    "            col = tmp_col\n",
    "        tmp_col = tmp_col.right\n",
    "    print(col.label)\n",
    "\n",
    "    # hide column \n",
    "    col.hideMe()\n",
    "\n",
    "    # go through its each row\n",
    "    row = col.down\n",
    "    print(row.ROW.label)\n",
    "    while row != col:\n",
    "\n",
    "        # add row to solution\n",
    "        solution.append(row)\n",
    "        log.append(f\"select R{row.ROW.label['R']}C{row.ROW.label['C']}={row.ROW.label['#']}\")\n",
    "\n",
    "        # hide row's columns\n",
    "        cell = row.right\n",
    "        while cell != row:\n",
    "            if type(cell) != rowHeader:\n",
    "                cell.COL.hideMe()\n",
    "            cell = cell.right\n",
    "\n",
    "        # go deeper\n",
    "        result = search(matrix, solution, log, k = k+1)\n",
    "        if result != None:\n",
    "            return result\n",
    "\n",
    "        # uncover columns and remove row from solution\n",
    "        solution.pop()\n",
    "        log.append(\"back\")\n",
    "        cell = row.left\n",
    "        while cell != row:\n",
    "            if type(cell) != rowHeader:\n",
    "                cell.COL.showMe()\n",
    "            cell = cell.left\n",
    "\n",
    "        # next row\n",
    "        row = row.down\n",
    "\n",
    "    # uncover column\n",
    "    col.showMe()\n",
    "    \n",
    "    return None\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
